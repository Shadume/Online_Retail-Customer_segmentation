{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrat de maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.graph_objects as go\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation du csv dans un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.read_csv('./clean_online_retail.csv')\n",
    "df = df_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 797815 entries, 0 to 797814\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   Invoice      797815 non-null  object        \n",
      " 1   StockCode    797815 non-null  object        \n",
      " 2   Description  797815 non-null  object        \n",
      " 3   Quantity     797815 non-null  int64         \n",
      " 4   InvoiceDate  797815 non-null  datetime64[ns]\n",
      " 5   Price        797815 non-null  float64       \n",
      " 6   Customer ID  797815 non-null  int64         \n",
      " 7   Country      797815 non-null  object        \n",
      " 8   TotalPrice   797815 non-null  float64       \n",
      " 9   cancelled    797815 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(3), object(4)\n",
      "memory usage: 60.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des dataframe filtrés, à +1jours, +15jours, +1mois, +2mois, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des noms des DataFrames\n",
    "df_filtered_names = [\"df_filtered_0\", \"df_filtered_J1\", \"df_filtered_J15\", \"df_filtered_M1\", \"df_filtered_M2\", \"df_filtered_M3\", \"df_filtered_M4\", \"df_filtered_M5\", \"df_filtered_M6\", \"df_filtered_M7\", \"df_filtered_M8\", \"df_filtered_M9\", \"df_filtered_M10\", \"df_filtered_M11\"]\n",
    "\n",
    "# Liste pour stocker les DataFrames\n",
    "df_filtered_list = []\n",
    "\n",
    "# Boucle pour créer les DataFrames et les stocker dans la liste\n",
    "for i, date in enumerate(['2010-12-31', '2011-01-01', '2011-01-15', '2011-01-31', '2011-02-28', '2011-03-31', '2011-04-30', '2011-05-31', '2011-06-30', '2011-07-31', '2011-08-31', '2011-09-30', '2011-10-31', '2011-11-28']):\n",
    "    df_name = df_filtered_names[i]  # Nom du DataFrame\n",
    "    df = df[df['InvoiceDate'] <= pd.to_datetime(date)]  # Filtrer les données\n",
    "    globals()[df_name] = df  # Stocker le DataFrame dans une variable globale\n",
    "    df_filtered_list.append(df)  # Ajouter le DataFrame à la liste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_filtered_list)<15:\n",
    "    df_filtered_list.append(df)\n",
    "    \n",
    "if \"df\" not in df_filtered_names:\n",
    "    df_filtered_names.append(\"df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filtered_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df\n",
    "# df_filtered_J1 = df[df['InvoiceDate'] <= pd.to_datetime('2011-01-01')]\n",
    "# df_filtered_J15 = df[df['InvoiceDate'] <= pd.to_datetime('2011-01-15')]\n",
    "# df_filtered_1 = df[df['InvoiceDate'] <= pd.to_datetime('2011-01-31')]\n",
    "# df_filtered_2 = df[df['InvoiceDate'] <= pd.to_datetime('2011-02-28')]\n",
    "# df_filtered_3 = df[df['InvoiceDate'] <= pd.to_datetime('2011-03-31')]\n",
    "# df_filtered_4 = df[df['InvoiceDate'] <= pd.to_datetime('2011-04-30')]\n",
    "# df_filtered_5 = df[df['InvoiceDate'] <= pd.to_datetime('2011-05-31')]\n",
    "# df_filtered_6 = df[df['InvoiceDate'] <= pd.to_datetime('2011-06-30')]\n",
    "# df_filtered_7 = df[df['InvoiceDate'] <= pd.to_datetime('2011-07-31')]\n",
    "# df_filtered_8 = df[df['InvoiceDate'] <= pd.to_datetime('2011-08-31')]\n",
    "# df_filtered_9 = df[df['InvoiceDate'] <= pd.to_datetime('2011-09-30')]\n",
    "# df_filtered_10 = df[df['InvoiceDate'] <= pd.to_datetime('2011-10-31')]\n",
    "# df_filtered_11 = df[df['InvoiceDate'] <= pd.to_datetime('2011-11-28')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature \"Cancellation Percentage\" pour tous les dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des noms des DataFrames\n",
    "df_gp_cancellation_names = [\"df_gp_cancellation_0\", \"df_gp_cancellation_J1\", \"df_gp_cancellation_J15\", \"df_gp_cancellation_M1\", \"df_gp_cancellation_M2\", \"df_gp_cancellation_M3\", \"df_gp_cancellation_M4\", \"df_gp_cancellation_M5\", \"df_gp_cancellation_M6\", \"df_gp_cancellation_M7\", \"df_gp_cancellation_M8\", \"df_gp_cancellation_M9\", \"df_gp_cancellation_M10\", \"df_gp_cancellation_M11\", \"df_gp_cancellation\"]\n",
    "\n",
    "# Liste pour stocker les DataFrames vides\n",
    "df_gp_cancellation_list = []\n",
    "\n",
    "# Boucle pour créer les DataFrames vides et les stocker dans la liste\n",
    "for df_name in df_gp_cancellation_names:\n",
    "    df = pd.DataFrame()  # Créer un DataFrame vide\n",
    "    globals()[df_name] = df  # Stocker le DataFrame dans une variable globale\n",
    "    df_gp_cancellation_list.append(df)  # Ajouter le DataFrame à la liste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gp_cancellation = pd.DataFrame()\n",
    "# df_gp_cancellation_J1 = pd.DataFrame()\n",
    "# df_gp_cancellation_J15 = pd.DataFrame()\n",
    "# df_gp_cancellation_1 = pd.DataFrame()\n",
    "# df_gp_cancellation_2 = pd.DataFrame()\n",
    "# df_gp_cancellation_3 = pd.DataFrame()\n",
    "# df_gp_cancellation_4 = pd.DataFrame()\n",
    "# df_gp_cancellation_5 = pd.DataFrame()\n",
    "# df_gp_cancellation_6 = pd.DataFrame()\n",
    "# df_gp_cancellation_7 = pd.DataFrame()\n",
    "# df_gp_cancellation_8 = pd.DataFrame()\n",
    "# df_gp_cancellation_9 = pd.DataFrame()\n",
    "# df_gp_cancellation_10 = pd.DataFrame()\n",
    "# df_gp_cancellation_11 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opérations pour chaque DataFrame\n",
    "# for df_filtered_name, df_gp_cancellation_name in zip(df_filtered_names_list, df_gp_cancellation_names_list):\n",
    "#     df_filtered = globals()[df_filtered_name]  # Accéder au DataFrame en utilisant son nom\n",
    "    \n",
    "#     # Opérations de regroupement et calcul du pourcentage d'annulation\n",
    "#     df_gp_cancellation_temp = df_filtered.groupby(\"Customer ID\").agg({\"cancelled\": \"sum\", \"Invoice\": \"count\"})\n",
    "#     df_gp_cancellation_temp = df_gp_cancellation_temp.rename(columns={\"cancelled\": \"TotalCancelled\", \"Invoice\": \"TotalInvoices\"})\n",
    "#     df_gp_cancellation_temp[\"CancellationPercentage\"] = (df_gp_cancellation_temp[\"TotalCancelled\"] / df_gp_cancellation_temp[\"TotalInvoices\"]) * 100\n",
    "    \n",
    "#     # Affecter les résultats au DataFrame correspondant\n",
    "#     df_gp_cancellation_name = df_gp_cancellation_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index(['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate',\n",
      "       'Price', 'Customer ID', 'Country', 'TotalPrice', 'cancelled'],\n",
      "      dtype='object')\n",
      "(422601, 10)\n",
      "Index([], dtype='object')\n",
      "(0, 0)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Customer ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(df_filtered\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     12\u001b[0m \u001b[39m# Opérations de regroupement et calcul du pourcentage d'annulation\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df_gp_cancellation_temp \u001b[39m=\u001b[39m df_filtered\u001b[39m.\u001b[39;49mgroupby(\u001b[39m\"\u001b[39;49m\u001b[39mCustomer ID\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39magg({\u001b[39m\"\u001b[39m\u001b[39mcancelled\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39msum\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mInvoice\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m     14\u001b[0m df_gp_cancellation_temp \u001b[39m=\u001b[39m df_gp_cancellation_temp\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mcancelled\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mTotalCancelled\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mInvoice\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mTotalInvoices\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m     15\u001b[0m df_gp_cancellation_temp[\u001b[39m\"\u001b[39m\u001b[39mCancellationPercentage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (df_gp_cancellation_temp[\u001b[39m\"\u001b[39m\u001b[39mTotalCancelled\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m/\u001b[39m df_gp_cancellation_temp[\u001b[39m\"\u001b[39m\u001b[39mTotalInvoices\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:8402\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   8399\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8400\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8402\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8403\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8404\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   8405\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8406\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8407\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   8408\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8409\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8410\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[1;32m   8411\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8412\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8413\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:965\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 965\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    966\u001b[0m         obj,\n\u001b[1;32m    967\u001b[0m         keys,\n\u001b[1;32m    968\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    969\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    970\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    971\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    972\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[1;32m    973\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    976\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    977\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:888\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    886\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    889\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    891\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Customer ID'"
     ]
    }
   ],
   "source": [
    "# Liste pour stocker les DataFrames de résultat\n",
    "df_gp_cancellation_results = []\n",
    "\n",
    "# Opérations pour chaque DataFrame\n",
    "for i in range(len(df_filtered_names)):\n",
    "    df_filtered_name = df_filtered_names[i]\n",
    "    df_gp_cancellation_name = df_gp_cancellation_list[i]\n",
    "    df_filtered = globals()[df_filtered_name]  # Accéder au DataFrame en utilisant son nom\n",
    "    print(df_filtered.columns)\n",
    "    print(df_filtered.shape)\n",
    "\n",
    "    # Opérations de regroupement et calcul du pourcentage d'annulation\n",
    "    df_gp_cancellation_temp = df_filtered.groupby(\"Customer ID\").agg({\"cancelled\": \"sum\", \"Invoice\": \"count\"})\n",
    "    df_gp_cancellation_temp = df_gp_cancellation_temp.rename(columns={\"cancelled\": \"TotalCancelled\", \"Invoice\": \"TotalInvoices\"})\n",
    "    df_gp_cancellation_temp[\"CancellationPercentage\"] = (df_gp_cancellation_temp[\"TotalCancelled\"] / df_gp_cancellation_temp[\"TotalInvoices\"]) * 100\n",
    "    \n",
    "    # Ajouter le DataFrame de résultat à la liste\n",
    "    df_gp_cancellation_results.append(df_gp_cancellation_temp)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features RFM pour tous les dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des noms des DataFrames\n",
    "rfm_df_names = [\"rfm_df_0\", \"rfm_df_J1\", \"rfm_df_J15\", \"rfm_df_M1\", \"rfm_df_M2\", \"rfm_df_M3\", \"rfm_df_M4\", \"rfm_df_M5\", \"rfm_df_M6\", \"rfm_df_M7\", \"rfm_df_M8\", \"rfm_df_M9\", \"rfm_df_M10\", \"rfm_df_M11\", \"rfm_df\"]\n",
    "\n",
    "# Liste pour stocker les noms des DataFrames\n",
    "rfm_df_names_list = []\n",
    "\n",
    "# Boucle pour créer les DataFrames vides et stocker leurs noms\n",
    "for df_name in rfm_df_names:\n",
    "    df = pd.DataFrame()  # Créer un DataFrame vide\n",
    "    globals()[df_name] = df  # Stocker le DataFrame dans une variable globale\n",
    "    rfm_df_names_list.append(df_name)  # Ajouter le nom du DataFrame à la liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfm_df = pd.DataFrame()\n",
    "# rfm_df_J1 = pd.DataFrame()\n",
    "# rfm_df_J15 = pd.DataFrame()\n",
    "# rfm_df_1 = pd.DataFrame()\n",
    "# rfm_df_2 = pd.DataFrame()\n",
    "# rfm_df_3 = pd.DataFrame()\n",
    "# rfm_df_4 = pd.DataFrame()\n",
    "# rfm_df_5 = pd.DataFrame()\n",
    "# rfm_df_6 = pd.DataFrame()\n",
    "# rfm_df_7 = pd.DataFrame()\n",
    "# rfm_df_8 = pd.DataFrame()\n",
    "# rfm_df_9 = pd.DataFrame()\n",
    "# rfm_df_10 = pd.DataFrame()\n",
    "# rfm_df_11 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'InvoiceDate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'InvoiceDate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m df_filtered \u001b[39m=\u001b[39m \u001b[39mglobals\u001b[39m()[df_name]  \u001b[39m# Accéder au DataFrame en utilisant son nom\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Calcul des valeurs RFM\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m last_date \u001b[39m=\u001b[39m df_filtered[\u001b[39m\"\u001b[39;49m\u001b[39mInvoiceDate\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mmax()\n\u001b[1;32m      7\u001b[0m recency \u001b[39m=\u001b[39m (last_date \u001b[39m-\u001b[39m df_filtered\u001b[39m.\u001b[39mgroupby(\u001b[39m\"\u001b[39m\u001b[39mCustomer ID\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m\"\u001b[39m\u001b[39mInvoiceDate\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mmax())\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mdays\n\u001b[1;32m      8\u001b[0m frequency \u001b[39m=\u001b[39m df_filtered\u001b[39m.\u001b[39mgroupby(\u001b[39m\"\u001b[39m\u001b[39mCustomer ID\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m\"\u001b[39m\u001b[39mInvoice\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mnunique()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'InvoiceDate'"
     ]
    }
   ],
   "source": [
    "# Opérations pour chaque DataFrame\n",
    "for df_filtered_name, rfm_df_name in zip(df_filtered_names_list, rfm_df_names_list):\n",
    "    df_filtered = globals()[df_name]  # Accéder au DataFrame en utilisant son nom\n",
    "    \n",
    "    # Calcul des valeurs RFM\n",
    "    last_date = df_filtered[\"InvoiceDate\"].max()\n",
    "    recency = (last_date - df_filtered.groupby(\"Customer ID\")[\"InvoiceDate\"].max()).dt.days\n",
    "    frequency = df_filtered.groupby(\"Customer ID\")[\"Invoice\"].nunique()\n",
    "    monetary_value = df_filtered.groupby(\"Customer ID\")[\"TotalPrice\"].sum()\n",
    "    \n",
    "    # Création du DataFrame RFM correspondant\n",
    "    rfm_df_temp = pd.DataFrame({\n",
    "        \"Recency\": recency,\n",
    "        \"Frequency\": frequency,\n",
    "        \"MonetaryValue\": monetary_value\n",
    "    })\n",
    "    \n",
    "    # Affecter les résultats au DataFrame correspondant\n",
    "    rfm_df_name = rfm_df_temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature \"AvgItemsPerOrder\" pour tous les dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des noms des DataFrames\n",
    "df_gp_nb_articles_mean_names = [\"df_gp_nb_articles_mean_0\", \"df_gp_nb_articles_mean_J1\", \"df_gp_nb_articles_mean_J15\", \"df_gp_nb_articles_mean_M1\", \"df_gp_nb_articles_mean_M2\", \"df_gp_nb_articles_mean_M3\", \"df_gp_nb_articles_mean_M4\", \"df_gp_nb_articles_mean_M5\", \"df_gp_nb_articles_mean_M6\", \"df_gp_nb_articles_mean_M7\", \"df_gp_nb_articles_mean_M8\", \"df_gp_nb_articles_mean_M9\", \"df_gp_nb_articles_mean_M10\", \"df_gp_nb_articles_mean_M11\", \"df_gp_nb_articles_mean\"]\n",
    "\n",
    "# Liste pour stocker les noms des DataFrames\n",
    "df_gp_nb_articles_mean_names_list = []\n",
    "\n",
    "# Boucle pour créer les DataFrames vides et stocker leurs noms\n",
    "for df_name in df_gp_nb_articles_mean_names:\n",
    "    df = pd.DataFrame()  # Créer un DataFrame vide\n",
    "    globals()[df_name] = df  # Stocker le DataFrame dans une variable globale\n",
    "    df_gp_nb_articles_mean_names_list.append(df_name)  # Ajouter le nom du DataFrame à la liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_gp_nb_articles_mean = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_J1 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_J15 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_1 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_2 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_3 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_4 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_5 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_6 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_7 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_8 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_9 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_10 = pd.DataFrame()\n",
    "# df_gp_nb_articles_mean_11 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opérations pour chaque DataFrame\n",
    "for df_filtered_name, df_gp_nb_articles_mean_name in zip(df_filtered_names_list, df_gp_nb_articles_mean_names_list):\n",
    "    df_filtered = globals()[df_name]  # Accéder au DataFrame en utilisant son nom\n",
    "    \n",
    "    # Opérations de regroupement et calcul de la moyenne du nombre d'articles par commande\n",
    "    df_gp_nb_articles_mean_temp = df_filtered.groupby(['Customer ID', 'Invoice']).agg({'Quantity': 'sum'})\n",
    "    df_gp_nb_articles_mean_temp = df_gp_nb_articles_mean_temp.groupby('Customer ID').mean()\n",
    "    df_gp_nb_articles_mean_temp.columns = ['AvgItemsPerOrder']\n",
    "    \n",
    "    # Affecter les résultats au DataFrame correspondant\n",
    "    df_gp_nb_articles_mean_name = df_gp_nb_articles_mean_temp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes pour le clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des noms des DataFrames\n",
    "df_rfm_spe_names = [\"df_rfm_spe_0\", \"df_rfm_spe_J1\", \"df_rfm_spe_J15\", \"df_rfm_spe_1\", \"df_rfm_spe_2\", \"df_rfm_spe_3\", \"df_rfm_spe_4\", \"df_rfm_spe_5\", \"df_rfm_spe_6\", \"df_rfm_spe_7\", \"df_rfm_spe_8\", \"df_rfm_spe_9\", \"df_rfm_spe_10\", \"df_rfm_spe_11\", \"df_rfm_spe\"]\n",
    "\n",
    "# Liste pour stocker les noms des DataFrames\n",
    "df_rfm_spe_names_list = []\n",
    "\n",
    "# Boucle pour créer les DataFrames vides et stocker leurs noms\n",
    "for df_name in df_rfm_spe_names:\n",
    "    df = pd.DataFrame()  # Créer un DataFrame vide\n",
    "    globals()[df_name] = df  # Stocker le DataFrame dans une variable globale\n",
    "    df_rfm_spe_names_list.append(df_name)  # Ajouter le nom du DataFrame à la liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opérations pour chaque DataFrame\n",
    "for df_filtered_name, rfm_df_name, df_gp_cancellation_name, df_gp_nb_articles_mean_name in zip(df_filtered_names_list, rfm_df_names_list, df_gp_cancellation_names_list, df_gp_nb_articles_mean_names_list):\n",
    "    df_filtered = globals()[df_filtered_name]  # Accéder au DataFrame en utilisant son nom\n",
    "    \n",
    "    # Calcul des valeurs RFM\n",
    "    df_rfm_spe_temp = df_filtered.groupby('Customer ID').agg({'Invoice': 'nunique','Quantity':'sum', 'TotalPrice':'sum'})\n",
    "    df_rfm_spe_temp.columns = ['TotalInvoices', 'TotalQuantity', 'TotalPrice']\n",
    "    df_rfm_spe_temp = df_rfm_spe_temp.merge(rfm_df_temp[\"Recency\"], on=\"Customer ID\")\n",
    "    df_rfm_spe_temp = df_rfm_spe_temp.merge(df_gp_cancellation_temp[\"CancellationPercentage\"], on=\"Customer ID\")\n",
    "    df_rfm_spe_temp = df_rfm_spe_temp.merge(df_gp_nb_articles_mean_temp[\"AvgItemsPerOrder\"], on=\"Customer ID\")\n",
    "\n",
    "    \n",
    "    # Affecter les résultats au DataFrame correspondant\n",
    "    globals()[rfm_df_name] = df_rfm_spe_temp\n",
    "    \n",
    "    # Enregistrer le DataFrame en tant que fichier CSV\n",
    "    filename = f\"{rfm_df_name}.csv\"\n",
    "    filepath = os.path.join(\"data ARI\", filename)\n",
    "    df_rfm_spe_temp.to_csv(filepath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Opérations pour chaque DataFrame\n",
    "# for df_name, rfm_df_name, df_gp_cancellation_name in zip([\"df\", \"df_filtered_J1\", \"df_filtered_J15\", \"df_filtered_1\", \"df_filtered_2\", \"df_filtered_3\", \"df_filtered_4\", \"df_filtered_5\", \"df_filtered_6\", \"df_filtered_7\", \"df_filtered_8\", \"df_filtered_9\", \"df_filtered_10\", \"df_filtered_11\"],\n",
    "#                                                         [df_rfm_spe, df_rfm_spe_J1, df_rfm_spe_J15, df_rfm_spe_1, df_rfm_spe_2, df_rfm_spe_3, df_rfm_spe_4, df_rfm_spe_5, df_rfm_spe_6, df_rfm_spe_7, df_rfm_spe_8, df_rfm_spe_9, df_rfm_spe_10, df_rfm_spe_11],\n",
    "#                                                         [df_gp_cancellation, df_gp_cancellation_J1, df_gp_cancellation_J15, df_gp_cancellation_1, df_gp_cancellation_2, df_gp_cancellation_3, df_gp_cancellation_4, df_gp_cancellation_5, df_gp_cancellation_6, df_gp_cancellation_7, df_gp_cancellation_8, df_gp_cancellation_9, df_gp_cancellation_10, df_gp_cancellation_11]):\n",
    "#     df_filtered = globals()[df_name]  # Accéder au DataFrame en utilisant son nom\n",
    "    \n",
    "#     # Calcul des valeurs RFM\n",
    "#     df_rfm_spe_temp = df_filtered.groupby('Customer ID').agg({'Invoice': 'nunique','Quantity':'sum', 'TotalPrice':'sum'})\n",
    "#     df_rfm_spe_temp.columns = ['TotalInvoices', 'TotalQuantity', 'TotalPrice']\n",
    "#     df_rfm_spe_temp = df_rfm_spe_temp.merge(rfm_df_temp[\"Recency\"], on=\"Customer ID\")\n",
    "#     df_rfm_spe_temp = df_rfm_spe_temp.merge(df_gp_cancellation_temp[\"CancellationPercentage\"], on=\"Customer ID\")\n",
    "#     df_rfm_spe_temp = df_rfm_spe_temp.merge(df_gp_nb_articles_mean_temp[\"AvgItemsPerOrder\"], on=\"Customer ID\")\n",
    "\n",
    "    \n",
    "#     # Affecter les résultats au DataFrame correspondant\n",
    "#     rfm_df_name = df_rfm_spe_temp\n",
    "    \n",
    "#     # Enregistrer le DataFrame en tant que fichier CSV\n",
    "#     filename = f\"{df_name}.csv\"\n",
    "#     filepath = os.path.join(\"data ARI\", filename)\n",
    "#     rfm_df_name.to_csv(filepath, index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Liste des noms des DataFrames\n",
    "# df_names = [\"df_rfm_spe\", \"df_rfm_spe_J1\", \"df_rfm_spe_J15\", \"df_rfm_spe_1\", \"df_rfm_spe_2\", \"df_rfm_spe_3\", \"df_rfm_spe_4\", \"df_rfm_spe_5\", \"df_rfm_spe_6\", \"df_rfm_spe_7\", \"df_rfm_spe_8\", \"df_rfm_spe_9\", \"df_rfm_spe_10\", \"df_rfm_spe_11\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Instanciation du StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Boucle pour normaliser les données\n",
    "for df_name in df_rfm_spe_names:\n",
    "    df = globals()[df_name]  # Accéder au DataFrame en utilisant son nom\n",
    "    \n",
    "    # Sélection des colonnes à normaliser\n",
    "    columns_to_normalize = [\"TotalInvoices\", \"TotalQuantity\", \"TotalPrice\", \"Recency\", \"CancellationPercentage\", \"AvgItemsPerOrder\"]\n",
    "    \n",
    "    # Normalisation des valeurs\n",
    "    df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28ff26c65758d064959116f1d9c8fbca26d00c18c6d798db5e6a86c21bd645e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
